# ğŸŒ Web Intelligence Platform

**Intelligent discovery and scoring of website extraction surfaces for LLM-driven scrapers.**

## Quick Start (Docker)

### Prerequisites
- Docker & Docker Compose
- Git

### 1. Clone & Navigate
```bash
cd /Users/naouri/Downloads/Web\ Intelligence\ Platform
```

### 2. Start Services
```bash
docker-compose up --build
```

This will:
- âœ… Start PostgreSQL database
- âœ… Start Redis cache
- âœ… Start RabbitMQ queue
- âœ… Start FastAPI backend (http://localhost:8000)
- âœ… Start React frontend (http://localhost:3000)

### 3. Access the Platform

- **Dashboard**: http://localhost:3000
- **API Docs**: http://localhost:8000/docs
- **RabbitMQ**: http://localhost:15672 (guest/guest)

## Use Supabase locally (optional)

You can use Supabaseâ€™s local Postgres instead of the Docker Postgres:

```bash
# 1) Start Supabase local (macOS + Docker required)
bash scripts/supabase_local.sh

# 2) Set DATABASE_URL for backend
export DATABASE_URL=postgresql+asyncpg://postgres:postgres@127.0.0.1:54322/postgres

# 3) Run database migrations
(cd backend && DATABASE_URL=$DATABASE_URL bash scripts/db_migrate.sh)

# 4) Run backend against Supabase Postgres
(cd backend && DATABASE_URL=$DATABASE_URL uvicorn app.main:app --host 0.0.0.0 --port 8000)
```

Notes:
- Supabase CLI will run Postgres on 127.0.0.1:54322 with user/password `postgres`.
- Our app uses SQLAlchemy; no code changes required.
- Keep Redis (docker-compose) running or point REDIS_URL to your Redis.

## Development Setup (Local)

### Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Start PostgreSQL, Redis, RabbitMQ (or use docker-compose for those only)
# Then:
uvicorn app.main:app --reload
```

API will be at: http://localhost:8000
Docs at: http://localhost:8000/docs

### Frontend

```bash
cd frontend
npm install
npm start
```

App will open at: http://localhost:3000

## Architecture

```
Frontend (React)
    â†“
API Gateway (FastAPI)
    â†“
â”œâ”€â”€ Sites Service
â”œâ”€â”€ Jobs Service
â”œâ”€â”€ Blueprints Service
â”œâ”€â”€ Analytics Service
    â†“
Database (PostgreSQL)
Cache (Redis)
Queue (RabbitMQ)
```

## API Endpoints

### Sites
- `POST /api/v1/sites` - Create site
- `GET /api/v1/sites` - List sites
- `GET /api/v1/sites/{site_id}` - Get site
- `PUT /api/v1/sites/{site_id}` - Update site
- `DELETE /api/v1/sites/{site_id}` - Delete site

### Jobs
- `POST /api/v1/jobs` - Create job
- `GET /api/v1/jobs` - List jobs
- `GET /api/v1/jobs/{job_id}` - Get job
- `POST /api/v1/jobs/{job_id}/cancel` - Cancel job
- `POST /api/v1/jobs/{job_id}/retry` - Retry job

### Blueprints
- `GET /api/v1/blueprints/sites/{site_id}/latest` - Get latest
- `GET /api/v1/blueprints/{blueprint_id}` - Get blueprint
- `GET /api/v1/blueprints/sites/{site_id}/versions` - List versions
- `POST /api/v1/blueprints/{blueprint_id}/rollback` - Rollback
- `GET /api/v1/blueprints/{blueprint_id}/export` - Export

### Analytics
- `GET /api/v1/analytics/dashboard` - Dashboard metrics
- `GET /api/v1/analytics/sites/{site_id}/metrics` - Site metrics
- `GET /api/v1/analytics/methods/performance` - Method comparison

## Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”‚   â”œâ”€â”€ database.py          # DB connection
â”‚   â”‚   â”œâ”€â”€ models.py            # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schemas.py           # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ routes_sites.py      # Sites endpoints
â”‚   â”‚   â”œâ”€â”€ routes_jobs.py       # Jobs endpoints
â”‚   â”‚   â”œâ”€â”€ routes_blueprints.py # Blueprints endpoints
â”‚   â”‚   â”œâ”€â”€ routes_analytics.py  # Analytics endpoints
â”‚   â”‚   â””â”€â”€ routes_auth.py       # Auth endpoints (JWT)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ alembic.ini
â”‚   â”œâ”€â”€ migrations/
â”‚   â”‚   â””â”€â”€ versions/0001_initial.py
â”‚   â””â”€â”€ scripts/db_migrate.sh
â”œâ”€â”€ scripts/supabase_local.sh
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ DATABASE.sql
â”œâ”€â”€ docs/
â””â”€â”€ README.md
```

## Features

### Sites Management
- Add new websites for analysis
- View site fingerprints (CMS, framework, JS)
- Track discovery status
- Filter by platform/status

### Jobs System
- Real-time job monitoring
- Queue management
- Auto-retry on failure
- Cancel running jobs

### Blueprints
- Version control
- Category/endpoint extraction
- Selector generation
- Rollback support

### Analytics
- Discovery metrics
- Success rate tracking
- Method performance comparison
- Cost analysis

### Dashboard
- Overview metrics
- Real-time updates
- Status distribution
- Quality insights

## Next Steps

1. **Add Sites** - Click "Sites" â†’ "Add Site"
2. **Create Jobs** - Jobs will appear as sites are processed
3. **Monitor Progress** - Watch real-time updates on Jobs page
4. **Review Results** - Check blueprints and analytics

## Configuration

Set environment variables in `.env`:

```
DATABASE_URL=postgresql+asyncpg://wip:password@localhost:5432/web_intelligence
REDIS_URL=redis://localhost:6379/0
DEBUG=False
```

## Documentation

- `BUILD_GUIDE.md` - Setup guide
- `API_SPEC.md` - Full API documentation
- `IMPLEMENTATION.md` - Technical architecture
- `PROMPTS.md` - LLM prompt templates
- `/docs` - Project documentation

## Development Commands

### Backend
```bash
# Format
black app/

# Lint
flake8 app/

# Test
pytest

# Database
python -c "from app.database import init_db; await init_db()"
```

### Frontend
```bash
# Build
npm run build

# Test
npm test

# Eject (WARNING: irreversible)
npm eject
```

## Troubleshooting

### Database connection error
```bash
docker-compose down
docker-compose up --build
```

### Port already in use
```bash
# Change ports in docker-compose.yml
# Or kill existing process:
lsof -ti:8000 | xargs kill -9
```

### Frontend not updating
```bash
rm -rf frontend/node_modules frontend/build
npm install
npm start
```

## Status

- âœ… Backend API fully implemented
- âœ… Frontend dashboard complete
- âœ… Database schema ready
- âœ… Docker setup ready
- âœ… Supabase local supported
- â³ LLM integration (ready to add)
- â³ Workers (fingerprinter, browser, static)

## License

Proprietary - Web Intelligence Platform

## Support

See documentation in `/docs` directory.

---

**Ready to build intelligent scrapers?** ğŸš€

Start with the dashboard: http://localhost:3000

